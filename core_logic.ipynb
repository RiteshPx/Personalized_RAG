{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain chromadb sentence-transformers pypdf langchain-community google-generativeai langchain_chroma -qU\n"
      ],
      "metadata": {
        "id": "fx_T8KN6YgMv"
      },
      "id": "fx_T8KN6YgMv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import chromadb\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain_community.document_loaders import (\n",
        "    TextLoader,\n",
        "    Docx2txtLoader,\n",
        "    PyPDFLoader\n",
        ")"
      ],
      "metadata": {
        "id": "UsBXSLx8YkID"
      },
      "id": "UsBXSLx8YkID",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_documents(file_path: str):\n",
        "    \"\"\"\n",
        "    Load a document (PDF, DOCX, or TXT) into LangChain Document objects.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file uploaded by the user.\n",
        "\n",
        "    Returns:\n",
        "        list[Document]: List of LangChain Document objects.\n",
        "    \"\"\"\n",
        "    # Ensure file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "\n",
        "    # Get file extension\n",
        "    ext = os.path.splitext(file_path)[-1].lower()\n",
        "\n",
        "    # Choose loader based on file type\n",
        "    if ext == \".pdf\":\n",
        "        loader = PyPDFLoader(file_path)\n",
        "    elif ext == \".docx\":\n",
        "        loader = Docx2txtLoader(file_path)\n",
        "    elif ext == \".txt\":\n",
        "        loader = TextLoader(file_path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {ext}\")\n",
        "\n",
        "    # Load the document(s)\n",
        "    documents = loader.load()\n",
        "    print(f\"âœ… Loaded {len(documents)} document(s) from {file_path}\")\n",
        "\n",
        "    return documents\n",
        "\n",
        "\n",
        "# Choose your file\n",
        "pdf_path = \"/content/Data Science with Generative AI outline.pdf\"\n",
        "\n",
        "# Load PDF pages\n",
        "loader = load_documents(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "print(f\"âœ… Loaded {len(documents)} pages from {pdf_path}\")\n"
      ],
      "metadata": {
        "id": "iSPSbFt-Y6iR"
      },
      "id": "iSPSbFt-Y6iR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,       # characters per chunk\n",
        "    chunk_overlap=100,    # overlap for context continuity\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "chunks = splitter.split_documents(documents)\n",
        "\n",
        "print(f\"âœ… Split into {len(chunks)} text chunks\")\n"
      ],
      "metadata": {
        "id": "VnmCV0hpY9rN"
      },
      "id": "VnmCV0hpY9rN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed_text(texts):\n",
        "    return embedding_model.encode(texts).tolist()\n",
        "\n",
        "from langchain.embeddings.base import Embeddings\n",
        "\n",
        "class HFEmbedding(Embeddings):\n",
        "    def embed_documents(self, texts):\n",
        "        return embed_text(texts)\n",
        "    def embed_query(self, text):\n",
        "        return embed_text([text])[0]\n"
      ],
      "metadata": {
        "id": "7SYUsWlzZAtQ"
      },
      "id": "7SYUsWlzZAtQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb.config import Settings\n",
        "\n",
        "client = chromadb.Client(Settings(persist_directory=\"./rag_db\"))\n",
        "collection_name = \"pdf_knowledge\"\n",
        "\n",
        "vectorstore = Chroma(\n",
        "    client=client,\n",
        "    collection_name=collection_name,\n",
        "    embedding_function=HFEmbedding()\n",
        ")\n",
        "\n",
        "# Add chunks to vectorstore\n",
        "texts = [chunk.page_content for chunk in chunks]\n",
        "metadatas = [chunk.metadata for chunk in chunks]\n",
        "\n",
        "vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
        "\n",
        "print(\"âœ… ChromaDB populated successfully with PDF chunks!\")\n"
      ],
      "metadata": {
        "id": "dHjDOrc-ZDzt"
      },
      "id": "dHjDOrc-ZDzt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD9caRAI6oChsXLC7uDWB8FcSPcEP_oixg\"\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "def generate_answer(context, question):\n",
        "    prompt = f\"\"\"Answer the question based only on the following context:\n",
        "    {context}\n",
        "    Question: {question}\"\"\"\n",
        "\n",
        "    response = genai.GenerativeModel(\"gemini-2.5-flash\").generate_content(prompt)\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "dhCtvTp_ZG0m"
      },
      "id": "dhCtvTp_ZG0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question(question):\n",
        "    docs = retriever.invoke(question)\n",
        "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "    answer = generate_answer(context, question)\n",
        "    return answer\n",
        "\n",
        "question = \"name of some project that will perform ?\"\n",
        "response = ask_question(question)\n",
        "print(\"ðŸ¤– Answer:\", response)\n"
      ],
      "metadata": {
        "id": "5G6RLA0vZP12"
      },
      "id": "5G6RLA0vZP12",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}